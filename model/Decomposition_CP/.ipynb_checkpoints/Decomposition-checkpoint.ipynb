{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "noble-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mobile-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensor_decomposer(object):\n",
    "    def __init__(self):\n",
    "        super(tensor_decomposer, self).__init__()\n",
    "        self.approx = 0  # Approximation error (mean approximation if multiple decompositions)\n",
    "        self.approx_list = []  # List of approximations in case of several decompositions\n",
    "        self.dim_drop = 0  # Parameters reduction\n",
    "        self.original_param_list = []  # List of original parameters (in case of multiple layers)\n",
    "        self.new_param_list = []  # List of new parameters (in case of multiple layers)\n",
    "\n",
    "    def cp_decomposition_conv_layer(self, layer, rank):\n",
    "        \n",
    "        #On recupere les poids du kernel\n",
    "        t = tl.tensor(layer.weight.data)\n",
    "        \n",
    "        #On recupere la shape\n",
    "        a, b, c, d = np.shape(t)\n",
    "        \n",
    "        #On calcul le nombre de parametrer\n",
    "        dim_t = a * b * c * d\n",
    "\n",
    "        # Perform CP decomposition on the layer weight tensorly.\n",
    "        dec = parafac(t, rank=rank, init='random')\n",
    "        \n",
    "        #On reconstruit notre nouveau kernel en entier\n",
    "        recomp_tensor = tl.kruskal_to_tensor(dec)\n",
    "        \n",
    "        #On recup√®re la norme de notre kernel\n",
    "        norm_t = np.linalg.norm(t)\n",
    "        \n",
    "        #Calcul d'erreur entre les deux matrices.\n",
    "        self.approx_list.append(np.linalg.norm(recomp_tensor - t) / norm_t)\n",
    "        \n",
    "        #On sauvegarde l'erreur moyenne\n",
    "        self.approx = np.mean(self.approx_list)\n",
    "        print(self.approx)\n",
    "\n",
    "        self.original_param_list.append(dim_t)\n",
    "        self.new_param_list.append(rank * (a + b + c + d))\n",
    "        self.dim_drop = dim_t /(rank * (a + b + c + d))\n",
    "\n",
    "        for i in range(len(dec.factors)):\n",
    "            dec.factors[i] = torch.tensor(dec.factors[i])\n",
    "        \n",
    "        #Decomposition de notre kernel\n",
    "        last, first, vertical, horizontal = dec.factors\n",
    "        \n",
    "        \n",
    "        #Creation des 4 nouvelles couches de convolution\n",
    "        pointwise_s_to_r_layer = torch.nn.Conv2d(in_channels=first.shape[0],\n",
    "                                                 out_channels=first.shape[1], kernel_size=1, stride=1, padding=0,\n",
    "                                                 dilation=layer.dilation, bias=False)\n",
    "\n",
    "        depthwise_vertical_layer = torch.nn.Conv2d(in_channels=vertical.shape[1],\n",
    "                                                   out_channels=vertical.shape[1], kernel_size=(vertical.shape[0], 1),\n",
    "                                                   stride=1, padding=(layer.padding[0], 0), dilation=layer.dilation,\n",
    "                                                   groups=vertical.shape[1], bias=False)\n",
    "\n",
    "        depthwise_horizontal_layer = \\\n",
    "            torch.nn.Conv2d(in_channels=horizontal.shape[1],\n",
    "                            out_channels=horizontal.shape[1],\n",
    "                            kernel_size=(1, horizontal.shape[0]), stride=layer.stride,\n",
    "                            padding=(0, layer.padding[0]),\n",
    "                            dilation=layer.dilation, groups=horizontal.shape[1], bias=False)\n",
    "\n",
    "        pointwise_r_to_t_layer = torch.nn.Conv2d(in_channels=last.shape[1],\n",
    "                                                 out_channels=last.shape[0], kernel_size=1, stride=1,\n",
    "                                                 padding=0, dilation=layer.dilation, bias=True)\n",
    "        \n",
    "        #Creation de biais\n",
    "        pointwise_r_to_t_layer.bias.data = layer.bias.data\n",
    "        \n",
    "    \n",
    "        #On met les poids obtenus precedement au bon format!\n",
    "        depthwise_horizontal_layer.weight.data = \\\n",
    "            torch.transpose(horizontal, 1, 0).unsqueeze(1).unsqueeze(1)\n",
    "        depthwise_vertical_layer.weight.data = \\\n",
    "            torch.transpose(vertical, 1, 0).unsqueeze(1).unsqueeze(-1)\n",
    "        pointwise_s_to_r_layer.weight.data = \\\n",
    "            torch.transpose(first, 1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "        pointwise_r_to_t_layer.weight.data = last.unsqueeze(-1).unsqueeze(-1)\n",
    "    \n",
    "        #Retou des 4 couches de convolution\n",
    "        new_layers = [pointwise_s_to_r_layer, depthwise_vertical_layer,\n",
    "                      depthwise_horizontal_layer, pointwise_r_to_t_layer]\n",
    "\n",
    "        return nn.Sequential(*new_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ambient-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomposition conv2D\n",
    "layer = nn.Conv2d(in_channels=20, out_channels=20, kernel_size=(4, 4))\n",
    "weight_conv2D= layer.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "civil-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need numpy\n",
    "dec = parafac(weight_conv2D.numpy(), rank=16, init='random')\n",
    "recomp_tensor = tl.kruskal_to_tensor(dec)\n",
    "for i in range(len(dec.factors)):\n",
    "            dec.factors[i] = torch.tensor(dec.factors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "shared-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decomposition de notre kernel\n",
    "last, first, vertical, horizontal = dec.factors\n",
    "        \n",
    "#Creation des 4 nouvelles couches de convolution\n",
    "pointwise_s_to_r_layer = torch.nn.Conv2d(in_channels=first.shape[0],\n",
    "                                        out_channels=first.shape[1], kernel_size=1, stride=1, padding=0,\n",
    "                                        dilation=layer.dilation, bias=False)\n",
    "\n",
    "depthwise_vertical_layer = torch.nn.Conv2d(in_channels=vertical.shape[1],\n",
    "                                            out_channels=vertical.shape[1], kernel_size=(vertical.shape[0], 1),\n",
    "                                            stride=1, padding=(layer.padding[0], 0), dilation=layer.dilation,\n",
    "                                            groups=vertical.shape[1], bias=False)\n",
    "\n",
    "depthwise_horizontal_layer = \\\n",
    "    torch.nn.Conv2d(in_channels=horizontal.shape[1],\n",
    "                    out_channels=horizontal.shape[1],\n",
    "                    kernel_size=(1, horizontal.shape[0]), stride=layer.stride,\n",
    "                    padding=(0, layer.padding[0]),\n",
    "                    dilation=layer.dilation, groups=horizontal.shape[1], bias=False)\n",
    "\n",
    "pointwise_r_to_t_layer = torch.nn.Conv2d(in_channels=last.shape[1],\n",
    "                                        out_channels=last.shape[0], kernel_size=1, stride=1,\n",
    "                                        padding=0, dilation=layer.dilation, bias=True)\n",
    "        \n",
    "#Creation de biais\n",
    "pointwise_r_to_t_layer.bias.data = layer.bias.data\n",
    "\n",
    "#On met les poids obtenus precedement au bon format!\n",
    "depthwise_horizontal_layer.weight.data = \\\n",
    "    torch.transpose(horizontal, 1, 0).unsqueeze(1).unsqueeze(1)\n",
    "depthwise_vertical_layer.weight.data = \\\n",
    "    torch.transpose(vertical, 1, 0).unsqueeze(1).unsqueeze(-1)\n",
    "pointwise_s_to_r_layer.weight.data = \\\n",
    "    torch.transpose(first, 1, 0).unsqueeze(-1).unsqueeze(-1)\n",
    "pointwise_r_to_t_layer.weight.data = last.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "new_layers = [pointwise_s_to_r_layer,\n",
    "            depthwise_horizontal_layer,\n",
    "              depthwise_vertical_layer,\n",
    "              pointwise_r_to_t_layer]\n",
    "\n",
    "out_put = nn.Sequential(*new_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "blind-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.rand(1,20, 16, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fixed-promise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.0239e-01, -1.6780e-01, -1.6706e-01],\n",
       "          [-1.3313e-01, -1.1274e-01, -1.0400e-01],\n",
       "          [-1.1836e-01, -7.5947e-02, -1.4010e-01],\n",
       "          [ 5.7882e-02, -1.5031e-01, -2.3211e-01],\n",
       "          [-1.4689e-01, -1.7267e-01, -2.9984e-01],\n",
       "          [-1.0042e-01, -7.6852e-02, -1.8044e-01],\n",
       "          [-6.6180e-02, -1.3535e-01, -1.5580e-01],\n",
       "          [-2.7268e-01, -1.0410e-01, -1.7369e-01],\n",
       "          [-1.5788e-01, -2.0184e-01, -8.8302e-02],\n",
       "          [-1.3874e-01, -2.0224e-01, -2.7327e-01],\n",
       "          [-1.6490e-01, -1.3918e-01, -7.0850e-02],\n",
       "          [-2.4102e-01, -1.1266e-01, -1.3923e-01],\n",
       "          [-1.5408e-01, -9.2510e-02, -6.7765e-02]],\n",
       "\n",
       "         [[ 1.8363e-02, -3.3683e-02, -1.6838e-01],\n",
       "          [-7.7320e-02, -1.2026e-01, -1.7643e-01],\n",
       "          [-1.0520e-01, -1.5888e-01, -1.3480e-01],\n",
       "          [ 7.4537e-02, -1.1008e-01, -8.6727e-02],\n",
       "          [-1.5429e-01, -6.5665e-02, -9.8322e-02],\n",
       "          [-2.4558e-01,  7.0500e-03, -7.9269e-02],\n",
       "          [-3.1690e-02, -6.6927e-02, -1.4886e-01],\n",
       "          [-2.8839e-01, -6.2889e-02, -5.1758e-03],\n",
       "          [-1.8253e-02, -9.7392e-02, -9.5116e-02],\n",
       "          [ 1.0734e-02, -9.8559e-02, -1.1332e-01],\n",
       "          [-2.0435e-01, -9.2864e-02,  2.1781e-02],\n",
       "          [-1.1815e-01, -1.1079e-01, -1.4881e-01],\n",
       "          [-6.8361e-02, -7.6931e-02, -4.0891e-02]],\n",
       "\n",
       "         [[ 5.3313e-03,  5.7211e-02,  1.2256e-01],\n",
       "          [-1.2239e-01,  2.0555e-02,  1.3335e-01],\n",
       "          [ 7.9161e-02,  6.5421e-02,  2.5728e-01],\n",
       "          [ 9.3382e-02,  1.5332e-01,  1.4087e-01],\n",
       "          [-6.2712e-03,  7.0553e-04,  1.0759e-01],\n",
       "          [-6.1998e-02,  1.8312e-02, -4.4147e-02],\n",
       "          [ 1.8673e-01, -6.1853e-02, -2.6181e-02],\n",
       "          [ 3.9121e-03,  3.8354e-02,  1.3048e-01],\n",
       "          [ 1.4719e-01,  1.1996e-02,  1.8113e-01],\n",
       "          [ 1.0353e-01, -4.5122e-02,  1.6820e-02],\n",
       "          [ 2.6203e-02, -1.0705e-02, -7.1998e-03],\n",
       "          [ 1.3596e-01, -9.2369e-02,  3.3947e-02],\n",
       "          [ 8.7080e-02, -3.3302e-02,  1.0699e-01]],\n",
       "\n",
       "         [[ 9.0389e-02,  1.0643e-01,  1.8876e-01],\n",
       "          [ 1.9325e-01,  1.2217e-01,  5.1737e-02],\n",
       "          [ 1.5961e-02,  1.0707e-01,  1.3674e-01],\n",
       "          [ 1.7893e-01,  2.0024e-01,  6.7866e-02],\n",
       "          [ 2.4857e-01,  1.9481e-01,  2.0689e-01],\n",
       "          [ 2.3036e-01,  2.9391e-01,  1.1868e-01],\n",
       "          [ 1.0626e-01,  1.2021e-01,  2.8550e-01],\n",
       "          [ 3.6341e-02,  1.1245e-01,  1.4796e-01],\n",
       "          [ 1.9384e-01,  1.9272e-01,  1.4342e-01],\n",
       "          [ 1.8089e-01,  1.7219e-01,  2.0369e-01],\n",
       "          [ 1.7613e-01,  2.6981e-01,  2.3843e-01],\n",
       "          [-1.6817e-02,  2.0750e-01,  1.0098e-01],\n",
       "          [ 1.8011e-01,  1.4158e-01,  1.1911e-01]],\n",
       "\n",
       "         [[-1.1626e-01,  2.1191e-03, -8.0189e-02],\n",
       "          [-1.3368e-01, -3.1797e-02, -3.2335e-02],\n",
       "          [-6.9765e-02, -1.9715e-01, -1.4252e-01],\n",
       "          [-1.7105e-01, -1.4814e-01, -1.3151e-01],\n",
       "          [-1.7652e-01, -1.4213e-01, -1.2204e-01],\n",
       "          [-1.9406e-01, -1.0196e-01, -1.0326e-01],\n",
       "          [-1.8927e-01, -5.5848e-02, -1.6703e-01],\n",
       "          [-1.5012e-01, -1.4644e-01, -5.4968e-02],\n",
       "          [-1.0224e-01, -1.0861e-01, -1.5172e-01],\n",
       "          [-7.2221e-02, -1.8650e-01, -5.1735e-02],\n",
       "          [-3.8873e-02, -1.5463e-01, -1.4032e-01],\n",
       "          [-9.7484e-02, -2.7685e-01, -4.5349e-02],\n",
       "          [-1.9399e-01, -7.2303e-02, -1.2441e-01]],\n",
       "\n",
       "         [[-1.0064e-01, -1.6778e-01, -2.0536e-01],\n",
       "          [-2.3969e-01, -1.6600e-01, -1.2383e-01],\n",
       "          [-1.9639e-01, -2.3017e-01, -2.2036e-01],\n",
       "          [-1.1111e-01, -2.0646e-01, -1.3683e-01],\n",
       "          [-2.5454e-01, -9.9970e-02, -3.0530e-01],\n",
       "          [-2.3868e-01, -7.5551e-03, -1.8446e-01],\n",
       "          [-1.1775e-01, -1.5528e-01, -2.4449e-01],\n",
       "          [-2.6664e-01, -1.8881e-01, -6.6592e-02],\n",
       "          [-2.3175e-01, -2.1708e-01, -2.0861e-01],\n",
       "          [-1.0603e-01, -1.7666e-01, -3.2249e-01],\n",
       "          [-1.7569e-01, -1.8258e-01, -1.7015e-01],\n",
       "          [-2.6403e-01, -3.2813e-01, -2.8952e-01],\n",
       "          [-2.8475e-01, -2.4373e-01, -1.8218e-01]],\n",
       "\n",
       "         [[-6.1242e-02, -6.9242e-02, -4.3339e-02],\n",
       "          [-9.2350e-02, -5.7264e-02,  7.2470e-02],\n",
       "          [-6.2386e-02, -1.0617e-01, -3.9463e-03],\n",
       "          [-1.5222e-01, -1.7417e-02, -4.6168e-02],\n",
       "          [-1.3187e-01, -8.4849e-02, -7.9096e-02],\n",
       "          [-1.7424e-01, -1.8128e-01, -6.8843e-02],\n",
       "          [-2.3817e-02, -1.3080e-01, -1.0284e-02],\n",
       "          [ 1.0670e-01, -1.0427e-01,  6.5797e-02],\n",
       "          [-9.2091e-02, -1.0316e-01, -5.8821e-02],\n",
       "          [-1.7725e-01, -9.1056e-02, -9.7769e-02],\n",
       "          [-7.7933e-02, -1.4540e-01, -1.8525e-01],\n",
       "          [-6.8060e-02, -1.8779e-01, -1.2786e-01],\n",
       "          [-1.1917e-01, -1.8415e-01,  1.2633e-02]],\n",
       "\n",
       "         [[-1.0081e-01, -1.5326e-01, -1.1563e-01],\n",
       "          [-3.4853e-02, -4.7845e-02, -3.7838e-02],\n",
       "          [ 4.9615e-03, -6.4834e-02, -5.4144e-02],\n",
       "          [-6.7846e-02, -8.9222e-02, -2.8661e-02],\n",
       "          [-3.1391e-02, -2.3511e-02, -1.8287e-01],\n",
       "          [-6.8927e-02, -1.2623e-01, -2.3196e-02],\n",
       "          [ 7.4074e-03, -1.5990e-01, -1.2478e-01],\n",
       "          [ 7.2276e-03, -1.0242e-01, -5.7387e-02],\n",
       "          [-1.9076e-01, -1.2450e-01, -1.8093e-02],\n",
       "          [-1.3980e-01, -1.0898e-04, -1.0740e-01],\n",
       "          [-2.0498e-01, -6.9863e-02, -1.5014e-02],\n",
       "          [-3.8345e-02, -1.9768e-01, -1.5738e-01],\n",
       "          [-1.1304e-01, -2.0149e-01, -2.7309e-03]],\n",
       "\n",
       "         [[-1.5709e-01, -1.6983e-01, -1.9283e-01],\n",
       "          [-1.3670e-01, -2.1749e-01, -2.6359e-01],\n",
       "          [-1.1322e-01, -3.9519e-02, -2.0920e-01],\n",
       "          [-1.1547e-01, -2.3157e-01, -1.8328e-01],\n",
       "          [-1.3621e-01, -2.0562e-01, -1.1243e-01],\n",
       "          [-1.1670e-01, -2.3427e-01, -1.4425e-01],\n",
       "          [-1.4630e-01, -1.2122e-01, -1.4216e-01],\n",
       "          [-1.4514e-01, -9.3176e-02, -2.3290e-01],\n",
       "          [-1.2838e-01, -1.6551e-01, -2.2815e-01],\n",
       "          [-1.6062e-01, -1.6797e-01, -1.7556e-01],\n",
       "          [-1.9486e-01, -1.7962e-01, -1.4971e-01],\n",
       "          [-7.0594e-06,  3.4261e-02, -7.7850e-02],\n",
       "          [-9.3711e-02, -1.3326e-01, -1.9085e-01]],\n",
       "\n",
       "         [[-2.0402e-01,  3.0879e-02, -1.1416e-01],\n",
       "          [-1.3825e-02, -1.3561e-02, -1.3275e-01],\n",
       "          [-1.4571e-01, -1.1435e-01, -2.6208e-01],\n",
       "          [-1.2609e-01, -9.5084e-02, -3.3587e-01],\n",
       "          [-7.3817e-02, -2.2674e-01, -1.5884e-01],\n",
       "          [-1.3699e-01, -2.4554e-01, -2.2740e-01],\n",
       "          [-2.0099e-01, -1.4731e-01, -1.3408e-01],\n",
       "          [-8.8333e-02, -1.9333e-01, -2.4009e-01],\n",
       "          [-6.9818e-02, -2.8549e-03, -2.2528e-01],\n",
       "          [-2.6864e-01, -1.0289e-01, -6.9992e-03],\n",
       "          [-1.5827e-01, -1.1084e-01, -2.0301e-01],\n",
       "          [-1.9348e-01, -1.7905e-01, -1.4694e-01],\n",
       "          [-1.7434e-01, -1.5715e-01, -1.7590e-01]],\n",
       "\n",
       "         [[-2.7534e-01, -4.3238e-01, -3.9930e-01],\n",
       "          [-1.9595e-01, -3.6353e-01, -3.3320e-01],\n",
       "          [-2.5642e-01, -3.2399e-01, -4.0721e-01],\n",
       "          [-2.0249e-01, -3.5475e-01, -3.5319e-01],\n",
       "          [-3.4788e-01, -3.5577e-01, -4.0394e-01],\n",
       "          [-3.1610e-01, -4.6300e-01, -2.8925e-01],\n",
       "          [-2.8149e-01, -3.2076e-01, -3.2018e-01],\n",
       "          [-2.8993e-01, -2.9387e-01, -3.5959e-01],\n",
       "          [-3.6643e-01, -3.7598e-01, -2.8024e-01],\n",
       "          [-4.4689e-01, -2.6714e-01, -3.5561e-01],\n",
       "          [-4.2937e-01, -3.8329e-01, -2.6782e-01],\n",
       "          [-2.4358e-01, -2.5646e-01, -2.6441e-01],\n",
       "          [-2.2212e-01, -2.5974e-01, -2.0176e-01]],\n",
       "\n",
       "         [[ 7.3319e-03,  4.9612e-03,  6.4028e-02],\n",
       "          [-2.4216e-02,  2.0503e-02, -2.0063e-02],\n",
       "          [-8.1392e-02,  1.2652e-01, -4.3669e-02],\n",
       "          [ 7.7352e-02,  4.2211e-02, -6.1117e-02],\n",
       "          [ 3.0337e-02, -2.4567e-02, -9.3559e-02],\n",
       "          [ 1.3975e-01,  8.7377e-02, -2.0262e-01],\n",
       "          [ 6.5658e-02,  4.5188e-02, -1.6151e-01],\n",
       "          [-9.9962e-02,  7.9661e-02, -1.3774e-01],\n",
       "          [ 6.5312e-02,  1.3375e-01, -6.9401e-02],\n",
       "          [ 3.9522e-02,  6.0784e-02, -7.0860e-02],\n",
       "          [-2.0775e-03,  4.9518e-02, -6.0544e-02],\n",
       "          [-5.4138e-02,  1.6367e-02, -9.1135e-02],\n",
       "          [ 1.6963e-02,  3.7116e-02, -1.3723e-01]],\n",
       "\n",
       "         [[ 1.3297e-01,  2.4421e-03,  1.1454e-01],\n",
       "          [-3.1070e-02,  3.1840e-02,  1.2218e-01],\n",
       "          [ 3.0322e-03, -3.8859e-02,  4.2871e-02],\n",
       "          [-1.6628e-01,  6.2227e-02,  1.3841e-01],\n",
       "          [-5.2792e-02,  1.0896e-01,  3.6018e-02],\n",
       "          [ 1.3846e-01,  1.1842e-01,  9.6962e-02],\n",
       "          [ 2.9890e-02,  1.7201e-01, -1.5271e-02],\n",
       "          [ 1.5742e-01,  1.4119e-01,  1.4704e-01],\n",
       "          [ 1.7783e-02,  1.4188e-01,  4.8742e-02],\n",
       "          [ 1.0296e-01,  1.5511e-01,  5.8697e-02],\n",
       "          [ 1.4901e-01,  4.9949e-02, -4.1931e-02],\n",
       "          [ 2.1009e-02, -8.0233e-02,  4.3581e-02],\n",
       "          [ 6.5596e-02,  2.1324e-01, -6.4528e-02]],\n",
       "\n",
       "         [[ 1.8035e-01,  1.4792e-01,  2.1635e-02],\n",
       "          [ 5.6170e-02,  4.1098e-02,  3.9290e-02],\n",
       "          [ 2.8153e-02,  1.6736e-03,  4.2012e-02],\n",
       "          [ 1.7983e-01,  1.3274e-01,  9.1767e-02],\n",
       "          [ 1.4831e-01,  1.7358e-01,  1.7062e-01],\n",
       "          [ 1.0708e-01,  2.0633e-01,  2.2581e-01],\n",
       "          [ 1.2680e-01,  1.2571e-01,  1.3876e-01],\n",
       "          [ 3.0506e-02,  1.0872e-01,  1.1924e-01],\n",
       "          [ 1.4466e-01,  1.6104e-01,  1.8440e-01],\n",
       "          [ 1.4730e-01,  1.5834e-01,  1.6507e-01],\n",
       "          [ 1.0733e-01,  1.6120e-01,  1.9387e-01],\n",
       "          [-1.9115e-02,  1.9326e-01,  6.5509e-02],\n",
       "          [ 1.5283e-01,  1.5883e-01,  1.4907e-01]],\n",
       "\n",
       "         [[ 6.8266e-02,  2.3479e-01,  7.6480e-02],\n",
       "          [-1.9240e-03,  1.8852e-01,  1.3392e-01],\n",
       "          [ 1.8472e-01,  2.2429e-01,  1.5801e-01],\n",
       "          [ 2.3191e-01,  1.6716e-01,  1.0876e-01],\n",
       "          [ 1.8852e-01,  1.0516e-01,  1.2100e-01],\n",
       "          [ 1.9375e-01,  1.8357e-01,  2.0827e-01],\n",
       "          [ 1.8282e-01,  5.1443e-02,  1.6036e-01],\n",
       "          [ 1.0123e-01,  6.6755e-02,  3.6183e-02],\n",
       "          [ 1.0165e-01,  8.3382e-02,  2.6931e-01],\n",
       "          [ 1.4764e-01,  6.7866e-02,  6.3505e-02],\n",
       "          [ 1.9136e-01,  1.8541e-01,  1.3604e-01],\n",
       "          [ 8.3132e-02,  2.1134e-01,  1.8154e-01],\n",
       "          [ 9.1523e-02,  1.6442e-01,  1.5155e-01]],\n",
       "\n",
       "         [[ 1.2823e-01,  1.2337e-01,  3.6897e-02],\n",
       "          [ 1.8486e-01,  1.1044e-01,  5.1221e-02],\n",
       "          [ 1.4429e-01,  6.4281e-02,  7.5398e-02],\n",
       "          [ 1.1563e-02,  1.1681e-02,  8.2478e-02],\n",
       "          [ 1.2548e-01,  1.0233e-01,  6.9587e-02],\n",
       "          [ 9.4296e-02,  1.5143e-02,  1.1825e-01],\n",
       "          [-3.5731e-02,  1.6336e-01, -2.6734e-02],\n",
       "          [ 1.1147e-01,  1.1910e-01, -6.4404e-02],\n",
       "          [ 6.1326e-02,  1.3988e-01,  5.8241e-02],\n",
       "          [ 8.4187e-02,  1.3914e-01,  2.1639e-01],\n",
       "          [ 6.3754e-02,  8.2441e-02,  1.3274e-01],\n",
       "          [ 6.6335e-02,  1.2458e-01,  1.0596e-01],\n",
       "          [ 6.5161e-02,  1.0940e-01,  2.8674e-02]],\n",
       "\n",
       "         [[-6.5334e-02,  1.3812e-01,  2.8218e-03],\n",
       "          [ 1.3039e-02,  1.4044e-01,  1.4329e-02],\n",
       "          [ 1.6967e-01,  8.8350e-02,  5.9707e-02],\n",
       "          [-2.6030e-02,  2.4682e-02,  1.3207e-02],\n",
       "          [ 6.7922e-02,  3.5442e-02,  5.4237e-03],\n",
       "          [ 7.0090e-02,  2.1780e-02,  1.5154e-01],\n",
       "          [-7.5005e-03, -2.4318e-02,  9.5329e-02],\n",
       "          [ 1.4325e-01, -3.7314e-02, -8.8196e-03],\n",
       "          [-4.9700e-02, -9.4912e-04,  1.0934e-01],\n",
       "          [ 1.1754e-02,  4.7371e-02,  5.4952e-02],\n",
       "          [ 5.7508e-02,  8.9986e-02,  3.9108e-02],\n",
       "          [ 3.3693e-02, -2.8233e-02,  1.0012e-01],\n",
       "          [-4.3236e-02,  2.9176e-02, -2.5176e-02]],\n",
       "\n",
       "         [[ 1.2735e-02,  6.8944e-03,  3.7040e-02],\n",
       "          [ 6.9500e-02,  1.0701e-01, -9.6042e-03],\n",
       "          [ 1.4518e-01,  4.4991e-02,  5.5097e-02],\n",
       "          [-1.7006e-01, -8.4786e-02,  6.8649e-02],\n",
       "          [ 7.6280e-02,  7.5857e-02,  4.6730e-02],\n",
       "          [ 1.5167e-01,  7.2164e-02,  2.8720e-01],\n",
       "          [-2.8589e-02,  9.9223e-02,  1.0670e-01],\n",
       "          [ 1.0396e-01,  9.3254e-02,  1.1663e-01],\n",
       "          [-8.8835e-02, -3.8201e-03,  4.4816e-02],\n",
       "          [ 1.3049e-01,  4.9354e-02,  1.1839e-01],\n",
       "          [ 2.9722e-02,  1.2347e-01,  1.8134e-01],\n",
       "          [ 1.1510e-01,  1.4588e-02,  1.6018e-01],\n",
       "          [ 2.9321e-03,  1.9309e-01,  8.9604e-03]],\n",
       "\n",
       "         [[-2.5460e-02, -1.5434e-01, -3.0055e-02],\n",
       "          [-5.2571e-02, -2.3179e-01, -1.9386e-01],\n",
       "          [-5.0163e-02, -1.4292e-01, -1.8935e-02],\n",
       "          [-1.4875e-01, -1.5113e-01, -5.5969e-02],\n",
       "          [-1.2240e-01,  1.8064e-02,  4.4853e-03],\n",
       "          [-6.4665e-02,  8.0749e-02, -1.8076e-02],\n",
       "          [-9.5273e-02, -4.8956e-02,  4.5378e-02],\n",
       "          [-1.3270e-01, -5.9607e-02,  4.1593e-02],\n",
       "          [ 1.1294e-02, -6.4999e-02, -1.1627e-01],\n",
       "          [ 3.6035e-02,  1.5996e-02, -4.0557e-02],\n",
       "          [-6.4930e-02,  1.1613e-02,  1.5352e-02],\n",
       "          [-5.3547e-02, -1.4238e-01, -4.1728e-02],\n",
       "          [-2.6244e-02, -1.3653e-01, -1.9630e-01]],\n",
       "\n",
       "         [[-5.6664e-03, -1.8136e-01,  1.1786e-02],\n",
       "          [-5.0844e-02, -1.2929e-01, -6.3249e-02],\n",
       "          [-1.1615e-01, -1.4452e-02, -4.6202e-02],\n",
       "          [-8.8892e-02, -1.5643e-01,  4.1863e-02],\n",
       "          [ 3.1257e-03, -2.7573e-02,  1.1809e-03],\n",
       "          [ 3.1363e-02,  1.1363e-02, -1.1087e-01],\n",
       "          [-4.6076e-02,  4.6791e-02, -1.9069e-01],\n",
       "          [-1.9902e-01,  4.9007e-02, -7.9705e-02],\n",
       "          [-2.7902e-02, -3.7057e-02, -1.7967e-01],\n",
       "          [ 9.4379e-02, -9.4940e-02, -4.1394e-02],\n",
       "          [-4.6142e-02, -5.5230e-02,  2.3136e-02],\n",
       "          [ 9.2712e-02,  4.6879e-02, -4.2908e-02],\n",
       "          [-2.0847e-02, -3.6789e-02, -5.8933e-02]]]],\n",
       "       grad_fn=<ThnnConv2DBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_put(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "explicit-anthropology",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recomp_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a5de569143fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecomp_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'recomp_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "layer.weight.data = torch.from_numpy(recomp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "global-union",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.0239e-01, -1.6780e-01, -1.6706e-01],\n",
       "          [-1.3313e-01, -1.1274e-01, -1.0400e-01],\n",
       "          [-1.1836e-01, -7.5947e-02, -1.4010e-01],\n",
       "          [ 5.7882e-02, -1.5031e-01, -2.3211e-01],\n",
       "          [-1.4689e-01, -1.7267e-01, -2.9984e-01],\n",
       "          [-1.0042e-01, -7.6852e-02, -1.8044e-01],\n",
       "          [-6.6180e-02, -1.3535e-01, -1.5580e-01],\n",
       "          [-2.7268e-01, -1.0410e-01, -1.7369e-01],\n",
       "          [-1.5788e-01, -2.0184e-01, -8.8302e-02],\n",
       "          [-1.3874e-01, -2.0224e-01, -2.7327e-01],\n",
       "          [-1.6490e-01, -1.3918e-01, -7.0850e-02],\n",
       "          [-2.4102e-01, -1.1266e-01, -1.3923e-01],\n",
       "          [-1.5408e-01, -9.2510e-02, -6.7765e-02]],\n",
       "\n",
       "         [[ 1.8363e-02, -3.3683e-02, -1.6838e-01],\n",
       "          [-7.7321e-02, -1.2026e-01, -1.7643e-01],\n",
       "          [-1.0520e-01, -1.5888e-01, -1.3480e-01],\n",
       "          [ 7.4537e-02, -1.1008e-01, -8.6727e-02],\n",
       "          [-1.5429e-01, -6.5665e-02, -9.8322e-02],\n",
       "          [-2.4558e-01,  7.0500e-03, -7.9269e-02],\n",
       "          [-3.1690e-02, -6.6927e-02, -1.4886e-01],\n",
       "          [-2.8839e-01, -6.2889e-02, -5.1756e-03],\n",
       "          [-1.8253e-02, -9.7392e-02, -9.5116e-02],\n",
       "          [ 1.0734e-02, -9.8559e-02, -1.1332e-01],\n",
       "          [-2.0435e-01, -9.2864e-02,  2.1781e-02],\n",
       "          [-1.1815e-01, -1.1079e-01, -1.4881e-01],\n",
       "          [-6.8361e-02, -7.6931e-02, -4.0891e-02]],\n",
       "\n",
       "         [[ 5.3313e-03,  5.7211e-02,  1.2256e-01],\n",
       "          [-1.2239e-01,  2.0555e-02,  1.3335e-01],\n",
       "          [ 7.9162e-02,  6.5421e-02,  2.5728e-01],\n",
       "          [ 9.3382e-02,  1.5332e-01,  1.4087e-01],\n",
       "          [-6.2712e-03,  7.0553e-04,  1.0759e-01],\n",
       "          [-6.1998e-02,  1.8312e-02, -4.4147e-02],\n",
       "          [ 1.8673e-01, -6.1853e-02, -2.6181e-02],\n",
       "          [ 3.9121e-03,  3.8354e-02,  1.3048e-01],\n",
       "          [ 1.4719e-01,  1.1996e-02,  1.8113e-01],\n",
       "          [ 1.0353e-01, -4.5122e-02,  1.6820e-02],\n",
       "          [ 2.6203e-02, -1.0705e-02, -7.1999e-03],\n",
       "          [ 1.3596e-01, -9.2369e-02,  3.3947e-02],\n",
       "          [ 8.7080e-02, -3.3303e-02,  1.0699e-01]],\n",
       "\n",
       "         [[ 9.0390e-02,  1.0643e-01,  1.8876e-01],\n",
       "          [ 1.9325e-01,  1.2217e-01,  5.1737e-02],\n",
       "          [ 1.5961e-02,  1.0707e-01,  1.3674e-01],\n",
       "          [ 1.7893e-01,  2.0024e-01,  6.7866e-02],\n",
       "          [ 2.4857e-01,  1.9481e-01,  2.0689e-01],\n",
       "          [ 2.3036e-01,  2.9391e-01,  1.1868e-01],\n",
       "          [ 1.0626e-01,  1.2021e-01,  2.8550e-01],\n",
       "          [ 3.6341e-02,  1.1245e-01,  1.4796e-01],\n",
       "          [ 1.9384e-01,  1.9272e-01,  1.4342e-01],\n",
       "          [ 1.8089e-01,  1.7219e-01,  2.0369e-01],\n",
       "          [ 1.7613e-01,  2.6981e-01,  2.3843e-01],\n",
       "          [-1.6817e-02,  2.0750e-01,  1.0098e-01],\n",
       "          [ 1.8011e-01,  1.4158e-01,  1.1911e-01]],\n",
       "\n",
       "         [[-1.1626e-01,  2.1192e-03, -8.0189e-02],\n",
       "          [-1.3368e-01, -3.1797e-02, -3.2335e-02],\n",
       "          [-6.9765e-02, -1.9715e-01, -1.4252e-01],\n",
       "          [-1.7105e-01, -1.4814e-01, -1.3151e-01],\n",
       "          [-1.7652e-01, -1.4213e-01, -1.2204e-01],\n",
       "          [-1.9406e-01, -1.0196e-01, -1.0326e-01],\n",
       "          [-1.8927e-01, -5.5848e-02, -1.6703e-01],\n",
       "          [-1.5012e-01, -1.4644e-01, -5.4968e-02],\n",
       "          [-1.0224e-01, -1.0861e-01, -1.5172e-01],\n",
       "          [-7.2221e-02, -1.8650e-01, -5.1735e-02],\n",
       "          [-3.8873e-02, -1.5463e-01, -1.4032e-01],\n",
       "          [-9.7484e-02, -2.7685e-01, -4.5349e-02],\n",
       "          [-1.9399e-01, -7.2303e-02, -1.2441e-01]],\n",
       "\n",
       "         [[-1.0064e-01, -1.6778e-01, -2.0536e-01],\n",
       "          [-2.3969e-01, -1.6600e-01, -1.2383e-01],\n",
       "          [-1.9639e-01, -2.3017e-01, -2.2036e-01],\n",
       "          [-1.1111e-01, -2.0646e-01, -1.3683e-01],\n",
       "          [-2.5454e-01, -9.9970e-02, -3.0530e-01],\n",
       "          [-2.3868e-01, -7.5550e-03, -1.8446e-01],\n",
       "          [-1.1775e-01, -1.5528e-01, -2.4449e-01],\n",
       "          [-2.6664e-01, -1.8881e-01, -6.6592e-02],\n",
       "          [-2.3175e-01, -2.1708e-01, -2.0861e-01],\n",
       "          [-1.0604e-01, -1.7666e-01, -3.2249e-01],\n",
       "          [-1.7569e-01, -1.8258e-01, -1.7015e-01],\n",
       "          [-2.6403e-01, -3.2813e-01, -2.8952e-01],\n",
       "          [-2.8475e-01, -2.4373e-01, -1.8218e-01]],\n",
       "\n",
       "         [[-6.1242e-02, -6.9242e-02, -4.3339e-02],\n",
       "          [-9.2350e-02, -5.7264e-02,  7.2470e-02],\n",
       "          [-6.2386e-02, -1.0617e-01, -3.9463e-03],\n",
       "          [-1.5222e-01, -1.7416e-02, -4.6168e-02],\n",
       "          [-1.3187e-01, -8.4849e-02, -7.9096e-02],\n",
       "          [-1.7424e-01, -1.8128e-01, -6.8843e-02],\n",
       "          [-2.3817e-02, -1.3080e-01, -1.0284e-02],\n",
       "          [ 1.0670e-01, -1.0427e-01,  6.5797e-02],\n",
       "          [-9.2091e-02, -1.0316e-01, -5.8821e-02],\n",
       "          [-1.7725e-01, -9.1056e-02, -9.7769e-02],\n",
       "          [-7.7933e-02, -1.4540e-01, -1.8525e-01],\n",
       "          [-6.8060e-02, -1.8779e-01, -1.2786e-01],\n",
       "          [-1.1917e-01, -1.8415e-01,  1.2633e-02]],\n",
       "\n",
       "         [[-1.0081e-01, -1.5326e-01, -1.1563e-01],\n",
       "          [-3.4853e-02, -4.7845e-02, -3.7838e-02],\n",
       "          [ 4.9616e-03, -6.4834e-02, -5.4144e-02],\n",
       "          [-6.7846e-02, -8.9221e-02, -2.8661e-02],\n",
       "          [-3.1391e-02, -2.3511e-02, -1.8287e-01],\n",
       "          [-6.8927e-02, -1.2623e-01, -2.3196e-02],\n",
       "          [ 7.4074e-03, -1.5990e-01, -1.2478e-01],\n",
       "          [ 7.2276e-03, -1.0242e-01, -5.7387e-02],\n",
       "          [-1.9076e-01, -1.2450e-01, -1.8094e-02],\n",
       "          [-1.3980e-01, -1.0896e-04, -1.0740e-01],\n",
       "          [-2.0498e-01, -6.9863e-02, -1.5014e-02],\n",
       "          [-3.8344e-02, -1.9768e-01, -1.5738e-01],\n",
       "          [-1.1304e-01, -2.0149e-01, -2.7309e-03]],\n",
       "\n",
       "         [[-1.5709e-01, -1.6983e-01, -1.9283e-01],\n",
       "          [-1.3670e-01, -2.1749e-01, -2.6359e-01],\n",
       "          [-1.1322e-01, -3.9519e-02, -2.0920e-01],\n",
       "          [-1.1547e-01, -2.3157e-01, -1.8328e-01],\n",
       "          [-1.3621e-01, -2.0562e-01, -1.1243e-01],\n",
       "          [-1.1670e-01, -2.3427e-01, -1.4425e-01],\n",
       "          [-1.4630e-01, -1.2122e-01, -1.4216e-01],\n",
       "          [-1.4514e-01, -9.3176e-02, -2.3290e-01],\n",
       "          [-1.2838e-01, -1.6551e-01, -2.2815e-01],\n",
       "          [-1.6062e-01, -1.6797e-01, -1.7556e-01],\n",
       "          [-1.9486e-01, -1.7962e-01, -1.4971e-01],\n",
       "          [-7.1116e-06,  3.4261e-02, -7.7850e-02],\n",
       "          [-9.3711e-02, -1.3325e-01, -1.9085e-01]],\n",
       "\n",
       "         [[-2.0402e-01,  3.0879e-02, -1.1416e-01],\n",
       "          [-1.3825e-02, -1.3561e-02, -1.3275e-01],\n",
       "          [-1.4571e-01, -1.1435e-01, -2.6208e-01],\n",
       "          [-1.2609e-01, -9.5084e-02, -3.3587e-01],\n",
       "          [-7.3817e-02, -2.2674e-01, -1.5884e-01],\n",
       "          [-1.3699e-01, -2.4554e-01, -2.2740e-01],\n",
       "          [-2.0099e-01, -1.4731e-01, -1.3408e-01],\n",
       "          [-8.8333e-02, -1.9333e-01, -2.4009e-01],\n",
       "          [-6.9818e-02, -2.8549e-03, -2.2528e-01],\n",
       "          [-2.6864e-01, -1.0289e-01, -6.9992e-03],\n",
       "          [-1.5827e-01, -1.1084e-01, -2.0301e-01],\n",
       "          [-1.9348e-01, -1.7905e-01, -1.4694e-01],\n",
       "          [-1.7434e-01, -1.5715e-01, -1.7590e-01]],\n",
       "\n",
       "         [[-2.7534e-01, -4.3238e-01, -3.9930e-01],\n",
       "          [-1.9595e-01, -3.6353e-01, -3.3320e-01],\n",
       "          [-2.5642e-01, -3.2399e-01, -4.0721e-01],\n",
       "          [-2.0249e-01, -3.5475e-01, -3.5319e-01],\n",
       "          [-3.4788e-01, -3.5577e-01, -4.0394e-01],\n",
       "          [-3.1610e-01, -4.6301e-01, -2.8925e-01],\n",
       "          [-2.8149e-01, -3.2076e-01, -3.2018e-01],\n",
       "          [-2.8993e-01, -2.9387e-01, -3.5959e-01],\n",
       "          [-3.6643e-01, -3.7598e-01, -2.8024e-01],\n",
       "          [-4.4689e-01, -2.6714e-01, -3.5561e-01],\n",
       "          [-4.2937e-01, -3.8329e-01, -2.6782e-01],\n",
       "          [-2.4358e-01, -2.5646e-01, -2.6441e-01],\n",
       "          [-2.2212e-01, -2.5974e-01, -2.0176e-01]],\n",
       "\n",
       "         [[ 7.3319e-03,  4.9612e-03,  6.4028e-02],\n",
       "          [-2.4216e-02,  2.0503e-02, -2.0063e-02],\n",
       "          [-8.1392e-02,  1.2652e-01, -4.3669e-02],\n",
       "          [ 7.7352e-02,  4.2211e-02, -6.1118e-02],\n",
       "          [ 3.0337e-02, -2.4567e-02, -9.3559e-02],\n",
       "          [ 1.3975e-01,  8.7378e-02, -2.0262e-01],\n",
       "          [ 6.5658e-02,  4.5188e-02, -1.6151e-01],\n",
       "          [-9.9962e-02,  7.9661e-02, -1.3774e-01],\n",
       "          [ 6.5312e-02,  1.3375e-01, -6.9401e-02],\n",
       "          [ 3.9522e-02,  6.0784e-02, -7.0860e-02],\n",
       "          [-2.0774e-03,  4.9518e-02, -6.0544e-02],\n",
       "          [-5.4138e-02,  1.6367e-02, -9.1135e-02],\n",
       "          [ 1.6963e-02,  3.7116e-02, -1.3723e-01]],\n",
       "\n",
       "         [[ 1.3297e-01,  2.4421e-03,  1.1454e-01],\n",
       "          [-3.1070e-02,  3.1840e-02,  1.2218e-01],\n",
       "          [ 3.0320e-03, -3.8859e-02,  4.2871e-02],\n",
       "          [-1.6628e-01,  6.2227e-02,  1.3841e-01],\n",
       "          [-5.2792e-02,  1.0896e-01,  3.6018e-02],\n",
       "          [ 1.3846e-01,  1.1842e-01,  9.6962e-02],\n",
       "          [ 2.9890e-02,  1.7201e-01, -1.5272e-02],\n",
       "          [ 1.5742e-01,  1.4119e-01,  1.4704e-01],\n",
       "          [ 1.7783e-02,  1.4188e-01,  4.8742e-02],\n",
       "          [ 1.0296e-01,  1.5511e-01,  5.8697e-02],\n",
       "          [ 1.4901e-01,  4.9949e-02, -4.1931e-02],\n",
       "          [ 2.1009e-02, -8.0233e-02,  4.3581e-02],\n",
       "          [ 6.5596e-02,  2.1324e-01, -6.4528e-02]],\n",
       "\n",
       "         [[ 1.8035e-01,  1.4792e-01,  2.1635e-02],\n",
       "          [ 5.6170e-02,  4.1098e-02,  3.9290e-02],\n",
       "          [ 2.8153e-02,  1.6736e-03,  4.2012e-02],\n",
       "          [ 1.7983e-01,  1.3274e-01,  9.1767e-02],\n",
       "          [ 1.4831e-01,  1.7358e-01,  1.7062e-01],\n",
       "          [ 1.0708e-01,  2.0633e-01,  2.2581e-01],\n",
       "          [ 1.2680e-01,  1.2571e-01,  1.3876e-01],\n",
       "          [ 3.0507e-02,  1.0872e-01,  1.1924e-01],\n",
       "          [ 1.4466e-01,  1.6104e-01,  1.8440e-01],\n",
       "          [ 1.4730e-01,  1.5834e-01,  1.6507e-01],\n",
       "          [ 1.0733e-01,  1.6120e-01,  1.9387e-01],\n",
       "          [-1.9115e-02,  1.9326e-01,  6.5509e-02],\n",
       "          [ 1.5283e-01,  1.5883e-01,  1.4907e-01]],\n",
       "\n",
       "         [[ 6.8266e-02,  2.3479e-01,  7.6480e-02],\n",
       "          [-1.9240e-03,  1.8852e-01,  1.3392e-01],\n",
       "          [ 1.8472e-01,  2.2429e-01,  1.5801e-01],\n",
       "          [ 2.3191e-01,  1.6716e-01,  1.0876e-01],\n",
       "          [ 1.8852e-01,  1.0516e-01,  1.2100e-01],\n",
       "          [ 1.9375e-01,  1.8357e-01,  2.0827e-01],\n",
       "          [ 1.8282e-01,  5.1443e-02,  1.6036e-01],\n",
       "          [ 1.0123e-01,  6.6755e-02,  3.6183e-02],\n",
       "          [ 1.0165e-01,  8.3382e-02,  2.6931e-01],\n",
       "          [ 1.4764e-01,  6.7866e-02,  6.3505e-02],\n",
       "          [ 1.9136e-01,  1.8541e-01,  1.3604e-01],\n",
       "          [ 8.3132e-02,  2.1134e-01,  1.8154e-01],\n",
       "          [ 9.1523e-02,  1.6442e-01,  1.5155e-01]],\n",
       "\n",
       "         [[ 1.2823e-01,  1.2337e-01,  3.6897e-02],\n",
       "          [ 1.8486e-01,  1.1044e-01,  5.1221e-02],\n",
       "          [ 1.4429e-01,  6.4281e-02,  7.5398e-02],\n",
       "          [ 1.1563e-02,  1.1681e-02,  8.2478e-02],\n",
       "          [ 1.2548e-01,  1.0233e-01,  6.9587e-02],\n",
       "          [ 9.4296e-02,  1.5143e-02,  1.1825e-01],\n",
       "          [-3.5731e-02,  1.6336e-01, -2.6734e-02],\n",
       "          [ 1.1147e-01,  1.1910e-01, -6.4404e-02],\n",
       "          [ 6.1326e-02,  1.3988e-01,  5.8241e-02],\n",
       "          [ 8.4187e-02,  1.3914e-01,  2.1639e-01],\n",
       "          [ 6.3754e-02,  8.2441e-02,  1.3274e-01],\n",
       "          [ 6.6335e-02,  1.2458e-01,  1.0596e-01],\n",
       "          [ 6.5161e-02,  1.0940e-01,  2.8674e-02]],\n",
       "\n",
       "         [[-6.5334e-02,  1.3812e-01,  2.8218e-03],\n",
       "          [ 1.3039e-02,  1.4044e-01,  1.4329e-02],\n",
       "          [ 1.6967e-01,  8.8350e-02,  5.9707e-02],\n",
       "          [-2.6030e-02,  2.4682e-02,  1.3207e-02],\n",
       "          [ 6.7922e-02,  3.5442e-02,  5.4237e-03],\n",
       "          [ 7.0090e-02,  2.1779e-02,  1.5154e-01],\n",
       "          [-7.5005e-03, -2.4318e-02,  9.5329e-02],\n",
       "          [ 1.4325e-01, -3.7314e-02, -8.8197e-03],\n",
       "          [-4.9700e-02, -9.4907e-04,  1.0934e-01],\n",
       "          [ 1.1754e-02,  4.7371e-02,  5.4952e-02],\n",
       "          [ 5.7508e-02,  8.9986e-02,  3.9108e-02],\n",
       "          [ 3.3693e-02, -2.8233e-02,  1.0012e-01],\n",
       "          [-4.3236e-02,  2.9176e-02, -2.5176e-02]],\n",
       "\n",
       "         [[ 1.2735e-02,  6.8943e-03,  3.7040e-02],\n",
       "          [ 6.9500e-02,  1.0701e-01, -9.6042e-03],\n",
       "          [ 1.4518e-01,  4.4991e-02,  5.5097e-02],\n",
       "          [-1.7006e-01, -8.4787e-02,  6.8649e-02],\n",
       "          [ 7.6280e-02,  7.5857e-02,  4.6730e-02],\n",
       "          [ 1.5167e-01,  7.2164e-02,  2.8720e-01],\n",
       "          [-2.8589e-02,  9.9223e-02,  1.0670e-01],\n",
       "          [ 1.0396e-01,  9.3254e-02,  1.1663e-01],\n",
       "          [-8.8835e-02, -3.8201e-03,  4.4816e-02],\n",
       "          [ 1.3049e-01,  4.9354e-02,  1.1839e-01],\n",
       "          [ 2.9722e-02,  1.2347e-01,  1.8134e-01],\n",
       "          [ 1.1510e-01,  1.4588e-02,  1.6018e-01],\n",
       "          [ 2.9322e-03,  1.9309e-01,  8.9603e-03]],\n",
       "\n",
       "         [[-2.5460e-02, -1.5434e-01, -3.0055e-02],\n",
       "          [-5.2571e-02, -2.3179e-01, -1.9386e-01],\n",
       "          [-5.0163e-02, -1.4292e-01, -1.8935e-02],\n",
       "          [-1.4875e-01, -1.5113e-01, -5.5969e-02],\n",
       "          [-1.2240e-01,  1.8064e-02,  4.4853e-03],\n",
       "          [-6.4665e-02,  8.0749e-02, -1.8076e-02],\n",
       "          [-9.5273e-02, -4.8956e-02,  4.5378e-02],\n",
       "          [-1.3270e-01, -5.9607e-02,  4.1593e-02],\n",
       "          [ 1.1294e-02, -6.4999e-02, -1.1627e-01],\n",
       "          [ 3.6035e-02,  1.5996e-02, -4.0557e-02],\n",
       "          [-6.4930e-02,  1.1613e-02,  1.5352e-02],\n",
       "          [-5.3547e-02, -1.4238e-01, -4.1728e-02],\n",
       "          [-2.6244e-02, -1.3653e-01, -1.9630e-01]],\n",
       "\n",
       "         [[-5.6664e-03, -1.8136e-01,  1.1786e-02],\n",
       "          [-5.0844e-02, -1.2929e-01, -6.3250e-02],\n",
       "          [-1.1615e-01, -1.4452e-02, -4.6202e-02],\n",
       "          [-8.8892e-02, -1.5643e-01,  4.1863e-02],\n",
       "          [ 3.1256e-03, -2.7573e-02,  1.1808e-03],\n",
       "          [ 3.1363e-02,  1.1363e-02, -1.1087e-01],\n",
       "          [-4.6076e-02,  4.6791e-02, -1.9069e-01],\n",
       "          [-1.9902e-01,  4.9007e-02, -7.9705e-02],\n",
       "          [-2.7902e-02, -3.7057e-02, -1.7967e-01],\n",
       "          [ 9.4379e-02, -9.4940e-02, -4.1394e-02],\n",
       "          [-4.6142e-02, -5.5230e-02,  2.3136e-02],\n",
       "          [ 9.2712e-02,  4.6879e-02, -4.2908e-02],\n",
       "          [-2.0847e-02, -3.6789e-02, -5.8933e-02]]]],\n",
       "       grad_fn=<MkldnnConvolutionBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "capable-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomposition conv2D\n",
    "layer = nn.Conv1d(in_channels=20, out_channels=20, kernel_size=4)\n",
    "weight_conv2D= layer.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "final-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = parafac(weight_conv2D.numpy(), rank=16, init='random')\n",
    "recomp_tensor = tl.kruskal_to_tensor(dec)\n",
    "for i in range(len(dec.factors)):\n",
    "            dec.factors[i] = torch.tensor(dec.factors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "palestinian-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnqueezeSecondDim(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UnqueezeSecondDim, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.unsqueeze(1)\n",
    "    \n",
    "class SqueezeThirdDim(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SqueezeThirdDim, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "monthly-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "last, cin, kernel = dec.factors\n",
    "unsqueeze_second = UnqueezeSecondDim()\n",
    "squeeze_third = SqueezeThirdDim()\n",
    "\n",
    "pointwise_horizontal_layer =\\\n",
    "torch.nn.Conv2d(in_channels=1,\n",
    "                out_channels=kernel.shape[1], kernel_size=(1, kernel.shape[0]),\n",
    "                stride=layer.stride, padding=layer.padding, bias=False)\n",
    "\n",
    "depthwise_vertical_layer = \\\n",
    "    torch.nn.Conv2d(in_channels=cin.shape[1],\n",
    "                    out_channels=cin.shape[1],\n",
    "                    kernel_size=(cin.shape[0], 1), stride=1,\n",
    "                    groups=cin.shape[1], bias=False)\n",
    "\n",
    "pointwise_r_to_t_layer = torch.nn.Conv1d(in_channels=last.shape[1],\n",
    "                                        out_channels=last.shape[0], kernel_size=1, stride=1,\n",
    "                                        padding=0, bias=True)\n",
    "        \n",
    "#Creation de biais\n",
    "pointwise_r_to_t_layer.bias.data = layer.bias.data\n",
    "\n",
    "#On met les poids obtenus precedement au bon format!\n",
    "pointwise_horizontal_layer.weight.data = \\\n",
    "    torch.transpose(kernel, 1, 0).unsqueeze(1).unsqueeze(1)\n",
    "depthwise_vertical_layer.weight.data = \\\n",
    "    torch.transpose(cin, 1, 0).unsqueeze(1).unsqueeze(-1)\n",
    "pointwise_r_to_t_layer.weight.data = last.unsqueeze(-1)\n",
    "\n",
    "new_layers = [unsqueeze_second,\n",
    "            pointwise_horizontal_layer,\n",
    "              depthwise_vertical_layer,\n",
    "              squeeze_third,\n",
    "              pointwise_r_to_t_layer]\n",
    "test = \n",
    "\n",
    "out_put = nn.Sequential(*new_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-peeing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "secure-browse",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=16, weight of size [16, 1, 20, 1], expected input[1, 1, 20, 10] to have 16 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-aa057b7d7a73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=16, weight of size [16, 1, 20, 1], expected input[1, 1, 20, 10] to have 16 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "test = torch.rand(1, 20, 10)\n",
    "out_put(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.weight.data = torch.from_numpy(recomp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hidden-highland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1160,  0.4565,  0.1882,  0.1913, -0.2787,  0.3059,  0.2433],\n",
       "         [-0.3255, -0.3622,  0.1038, -0.0264, -0.0322, -0.1329, -0.1673],\n",
       "         [-0.5303, -0.5183, -0.2888, -0.2795, -0.3304, -0.3309, -0.4189],\n",
       "         [ 0.4787,  0.1046,  0.0780,  0.1126,  0.2876, -0.0821,  0.1248],\n",
       "         [-0.1181, -0.1079, -0.0475, -0.2784,  0.0503, -0.2663, -0.2849],\n",
       "         [-0.0970,  0.1782, -0.2119, -0.4007, -0.1944, -0.2458, -0.3577],\n",
       "         [ 0.0966,  0.3262,  0.0766,  0.3221,  0.2643, -0.0690,  0.1703],\n",
       "         [ 0.2932,  0.1954, -0.1328,  0.2931,  0.3017,  0.1832,  0.1829],\n",
       "         [-0.4305, -0.2543, -0.4314, -0.3764, -0.4632, -0.0326, -0.4202],\n",
       "         [-0.2575, -0.4962, -0.1552, -0.3782,  0.1625, -0.2836, -0.0532],\n",
       "         [ 0.3599,  0.1485,  0.0278, -0.2048, -0.1499,  0.0222, -0.1815],\n",
       "         [-0.1280, -0.2523, -0.3435, -0.1740, -0.2645,  0.2781, -0.2838],\n",
       "         [ 0.3422, -0.0108, -0.0398, -0.0249, -0.2169,  0.2118,  0.2726],\n",
       "         [ 0.4265, -0.1257,  0.1116,  0.1414,  0.3231,  0.1018,  0.2262],\n",
       "         [ 0.1381, -0.0454,  0.2070,  0.0854,  0.0152,  0.0999,  0.0243],\n",
       "         [-0.1986, -0.1156, -0.0730, -0.3199, -0.0663, -0.3122,  0.0225],\n",
       "         [ 0.0131,  0.1037,  0.0547,  0.0761, -0.0301,  0.1095,  0.3559],\n",
       "         [-0.8638, -0.8585, -0.6699, -0.9939, -0.6849, -0.7827, -0.5905],\n",
       "         [ 0.6546,  0.3074,  0.5214,  0.5316,  0.5307,  0.4586,  0.8163],\n",
       "         [ 0.1635,  0.1195,  0.1374,  0.1507,  0.1742, -0.0824,  0.1929]]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-relation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
